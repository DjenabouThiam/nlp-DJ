{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c765d22a-d40a-4109-8641-f3fa3871739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3396dcb5-4100-418a-bb59-587e047c3e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Product Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike Air Force 1 '07</td>\n",
       "      <td>Men's Shoes</td>\n",
       "      <td>It doesn't get more legendary than this. Desig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike Air Max Dawn SE</td>\n",
       "      <td>Men's Shoes</td>\n",
       "      <td>Find out what moves you with the Air Max Dawn....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike SB Dunk Low Pro Premium</td>\n",
       "      <td>Skate Shoes</td>\n",
       "      <td>Pack your style—on your feet. Bringing a fresh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike Air Force 1 Mid '07 LX</td>\n",
       "      <td>Men's Shoes</td>\n",
       "      <td>The celebrations just keep coming. Unbox the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike Air Force 1 Mid '07</td>\n",
       "      <td>Men's Shoes</td>\n",
       "      <td>Got your fave colour yet? No worries, the Colo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Title     Subtitle  \\\n",
       "0          Nike Air Force 1 '07  Men's Shoes   \n",
       "1          Nike Air Max Dawn SE  Men's Shoes   \n",
       "2  Nike SB Dunk Low Pro Premium  Skate Shoes   \n",
       "3   Nike Air Force 1 Mid '07 LX  Men's Shoes   \n",
       "4      Nike Air Force 1 Mid '07  Men's Shoes   \n",
       "\n",
       "                                 Product Description  \n",
       "0  It doesn't get more legendary than this. Desig...  \n",
       "1  Find out what moves you with the Air Max Dawn....  \n",
       "2  Pack your style—on your feet. Bringing a fresh...  \n",
       "3  The celebrations just keep coming. Unbox the A...  \n",
       "4  Got your fave colour yet? No worries, the Colo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"NikeProductDescriptions (1).csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c85827-71a9-4bff-adb3-d64bf185b7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin-27619\\AppData\\Local\\Temp\\ipykernel_10360\\3376879734.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[filtered_df['Subtitle'].str.contains(\"Shorts\", case=False), 'Subtitle'] = \"Shorts\"\n"
     ]
    }
   ],
   "source": [
    "subtitles_to_keep = [\"Men's Shoes\", \"Men's T-Shirt\", \"Women's Shoes\", \"Skate Shoes\", \"Older Kids' T-Shirt\"]\n",
    "filtered_df = df[df['Subtitle'].isin(subtitles_to_keep) | df['Subtitle'].str.contains(\"Shorts\", case=False)]\n",
    "filtered_df.loc[filtered_df['Subtitle'].str.contains(\"Shorts\", case=False), 'Subtitle'] = \"Shorts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b77b87c7-7be6-4c01-abe1-7a4b031bea8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let classic, easy-to-wear AF-1 style rise to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There's no pedalling required to enjoy these s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rebuilt using insights from Grant Taylor, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When it came time to build his signature shoe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gear up for training. Play tag with your BFFs....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Product Description\n",
       "0  Let classic, easy-to-wear AF-1 style rise to t...\n",
       "1  There's no pedalling required to enjoy these s...\n",
       "2  Rebuilt using insights from Grant Taylor, the ...\n",
       "3  When it came time to build his signature shoe,...\n",
       "4  Gear up for training. Play tag with your BFFs...."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled = filtered_df[[\"Product Description\"]].dropna().sample(n=5, random_state=42).reset_index(drop=True)\n",
    "sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b21440-fed9-44a7-9cc9-748954eda4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Let classic, easy-to-wear AF-1 style rise to the occasion with the Nike Air Force 1 PLT.AF.ORM. Its elegantly shaped and lifted midsole delivers a proud, new voice to the hoops franchise. The leather on the upper breaks in easily and ages to soft perfection while the sculpted collar and pillowy heel keep it comfy. Captivate your audience.\n",
      "\n",
      "1. There's no pedalling required to enjoy these snug, stretchy shorts. Like your favourite leggings (and made from the same fabric as them), they're a perfect fit for warmer weather.\n",
      "\n",
      "2. Rebuilt using insights from Grant Taylor, the Nike SB Zoom Blazer Low Pro GT is a fresh take on a favourite skate shoe. The updated design has higher taping to give you more durability.\n",
      "\n",
      "3. When it came time to build his signature shoe, Ishod Wair was all in from start to finish. Infused with elements taken from the iconic hoops shoes of the '90s, (did you know that basketball was Ishod's 1st love?) and built with all the durability you need to skate hard—seriously, check out that new cupsole—the Nike SB Ishod Wair walks the line between original style and modern skate innovation.\n",
      "\n",
      "4. Gear up for training. Play tag with your BFFs. Or just do your favourite outdoor activity. The Nike Breezy shorts can help you do it all. Lightweight fabric helps you stay cool. The high-waisted design is versatile for your needs—wear them as-is, or roll the band up or down for the fit that's best for you. Plus, pair with a regular or crop top while you move.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, desc in enumerate(sampled[\"Product Description\"]):\n",
    "    print(f\"{i}. {desc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0768ecbd-135f-4a85-a4b9-455dc039c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(sampled[\"Product Description\"])\n",
    "#simularité cosinus\n",
    "cosine_sim_matrix = cosine_similarity(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b79c0f-dad8-4b4c-81b8-b7d8de0d0e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text 0</th>\n",
       "      <th>Text 1</th>\n",
       "      <th>Text 2</th>\n",
       "      <th>Text 3</th>\n",
       "      <th>Text 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text 0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118018</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.254499</td>\n",
       "      <td>0.131974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 1</th>\n",
       "      <td>0.118018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068609</td>\n",
       "      <td>0.090671</td>\n",
       "      <td>0.186769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 2</th>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.068609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191757</td>\n",
       "      <td>0.131979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 3</th>\n",
       "      <td>0.254499</td>\n",
       "      <td>0.090671</td>\n",
       "      <td>0.191757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 4</th>\n",
       "      <td>0.131974</td>\n",
       "      <td>0.186769</td>\n",
       "      <td>0.131979</td>\n",
       "      <td>0.157470</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Text 0    Text 1    Text 2    Text 3    Text 4\n",
       "Text 0  1.000000  0.118018  0.126474  0.254499  0.131974\n",
       "Text 1  0.118018  1.000000  0.068609  0.090671  0.186769\n",
       "Text 2  0.126474  0.068609  1.000000  0.191757  0.131979\n",
       "Text 3  0.254499  0.090671  0.191757  1.000000  0.157470\n",
       "Text 4  0.131974  0.186769  0.131979  0.157470  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_df = pd.DataFrame(cosine_sim_matrix, \n",
    "                         index=[f\"Text {i}\" for i in range(5)],\n",
    "                         columns=[f\"Text {i}\" for i in range(5)])\n",
    "cosine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "873c73a3-02a7-41cd-9e7c-2e9b02eda7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text 0</th>\n",
       "      <th>Text 1</th>\n",
       "      <th>Text 2</th>\n",
       "      <th>Text 3</th>\n",
       "      <th>Text 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text 0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.076087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 1</th>\n",
       "      <td>0.054795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.095890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 2</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>0.092105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 3</th>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 4</th>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Text 0    Text 1    Text 2    Text 3    Text 4\n",
       "Text 0  1.000000  0.054795  0.066667  0.108696  0.076087\n",
       "Text 1  0.054795  1.000000  0.089286  0.037500  0.095890\n",
       "Text 2  0.066667  0.089286  1.000000  0.088608  0.092105\n",
       "Text 3  0.108696  0.037500  0.088608  1.000000  0.050000\n",
       "Text 4  0.076087  0.095890  0.092105  0.050000  1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = sampled[\"Product Description\"].tolist()\n",
    "# matrice 5 x 5\n",
    "jaccard_matrix = pd.DataFrame(0.0, index=[f\"Text {i}\" for i in range(5)],\n",
    "                                    columns=[f\"Text {i}\" for i in range(5)])\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        set_i = set(texts[i].lower().split())\n",
    "        set_j = set(texts[j].lower().split())\n",
    "        intersection = set_i.intersection(set_j)\n",
    "        union = set_i.union(set_j)\n",
    "        score = len(intersection) / len(union)\n",
    "        jaccard_matrix.iloc[i, j] = score\n",
    "jaccard_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c6095ea-a369-4885-b6d0-96a885ad1c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin-27619\\anaconda3\\envs\\nlp_bert_env\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin-27619\\anaconda3\\envs\\nlp_bert_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43cdda96-844c-4262-8bc6-20018add4a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "def get_bert_embedding(text):\n",
    "    # Tokenisation de la phrase\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    \n",
    "    # Désactiver le gradient \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # On extrait le vecteur [CLS] comme représentation globale\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "    return cls_embedding\n",
    "embeddings = np.array([get_bert_embedding(desc) for desc in tqdm(sampled[\"Product Description\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56048749-f719-4074-8d6a-bb04fdaf9bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01908397, -0.33997953,  0.12956531, -0.64775836, -0.5130369 ,\n",
       "       -0.51012695,  0.30023336,  0.6959071 ,  0.41129142, -0.75964725],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][:10]  # Les 10 premières valeurs du 1er embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5aa5a-0868-430f-bb1d-2ece2f137e71",
   "metadata": {},
   "source": [
    "Analyse des résultats\n",
    "Avec la similarité cosinus appliquée à la matrice TF-IDF, on observe des scores modérés entre certains textes, notamment ceux traitant de chaussures de skate ou de sport. Cette méthode capte efficacement les recoupements lexicaux et met en évidence les descriptions qui partagent des termes techniques ou commerciaux fréquents. Par exemple, les textes contenant des mots comme \"durabilité\", \"chaussure\", ou \"Nike SB\" obtiennent des scores de similarité plus élevés entre eux. Cependant, cette approche reste sensible à la variation de vocabulaire, même pour des produits similaires.\n",
    "\n",
    "La similarité de Jaccard, plus stricte, donne des scores globalement faibles. Cela s’explique par le fait que cette méthode ne considère que la proportion de mots strictement identiques entre deux textes. Or, les descriptions marketing utilisent souvent des formulations variées pour parler de produits proches. Même deux textes décrivant des shorts ou des chaussures auront peu de mots en commun au sens strict, ce qui réduit leur score, malgré une proximité sémantique.\n",
    "\n",
    "En revanche, avec la méthode BERT basée sur les embeddings sémantiques, les résultats apparaissent plus cohérents du point de vue du sens. Cette approche capture les similarités même lorsque les mots diffèrent, ce qui permet de reconnaître comme proches des textes qui parlent du même type de produit ou qui remplissent une même fonction (par exemple : confort, performance, sport). BERT parvient à regrouper des textes qui seraient faiblement liés selon TF-IDF ou Jaccard, ce qui en fait une méthode particulièrement pertinente pour des tâches où la signification prime sur la forme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c9b935-e952-4818-aa73-fecee5282f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_bert_env]",
   "language": "python",
   "name": "conda-env-nlp_bert_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
