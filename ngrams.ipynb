{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f9a3a4-9203-4ecc-b219-f74291810736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\admin-27619\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin-27619\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', 'recent', 'primary', 'election', 'produced', 'no', 'evidence', 'that', 'any', 'irregularities', 'took']\n"
     ]
    }
   ],
   "source": [
    "#!pip install nltk\n",
    "# corpus \"brown\"\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')  #  tokenisation\n",
    "from nltk.corpus import brown\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "\n",
    "# Récupération des mots du corpus\n",
    "tokenized_text = brown.words()\n",
    "\n",
    "# On convertit en minuscules et on enlève la ponctuation\n",
    "cleaned_tokens = [word.lower() for word in tokenized_text if word.isalpha()]\n",
    "\n",
    "# Affichage des 20 premiers mots nettoyés\n",
    "print(cleaned_tokens[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad1aba3-f08f-48fe-bae5-2e820d117a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def get_ngrams_frequencies(tokens, n):\n",
    "   \n",
    "    # DataFrame avec les n-grams et leur fréquence d'apparition.\n",
    " \n",
    "    n_grams = list(ngrams(tokens, n))\n",
    "    freq_dist = Counter(n_grams)\n",
    "    df = pd.DataFrame(freq_dist.items(), columns=['ngram', 'frequency'])\n",
    "    df = df.sort_values(by='frequency', ascending=False).reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67bd7ff0-4963-41af-a6bf-fc5d7b1b09ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ngram  frequency\n",
      "0    (of, the)       9774\n",
      "1    (in, the)       6156\n",
      "2    (to, the)       3525\n",
      "3    (on, the)       2491\n",
      "4   (and, the)       2307\n",
      "5   (for, the)       1862\n",
      "6     (to, be)       1718\n",
      "7    (at, the)       1677\n",
      "8  (with, the)       1545\n",
      "9      (of, a)       1502\n"
     ]
    }
   ],
   "source": [
    "# Exemple avec des bigrams\n",
    "bigrams_df = get_ngrams_frequencies(cleaned_tokens, n=2)\n",
    "print(bigrams_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12193b6d-a7fd-4c8a-b2f6-2cb91e428790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_words(ngram_df, input_seq, n=2, k=5):\n",
    "    #Prédit les k mots les plus probables suivant une séquence de (n-1) mots.\n",
    "    # Filtrer les n-grams qui commencent par la séquence donnée\n",
    "    candidates = ngram_df[ngram_df['ngram'].apply(lambda x: x[:n-1] == input_seq)]\n",
    "    # Trier par fréquence\n",
    "    candidates = candidates.sort_values(by='frequency', ascending=False)\n",
    "    # Retourner les k premiers mots suivants\n",
    "    return [ngram[-1] for ngram in candidates['ngram'].head(k)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aadd90f-86f3-44c5-9665-1380051275f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'a', 'his', 'this', 'which']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_words(bigrams_df, input_seq=(\"in\",), n=2, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9b5115-77a2-41e7-949a-65cfbfd9aac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'be', 'a']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_words(bigrams_df, input_seq=(\"to\",), n=2, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8698ee8a-7f1a-4c55-8279-36290df6869e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ngram  frequency\n",
      "0         (one, of, the)        404\n",
      "1  (the, united, states)        337\n",
      "2         (as, well, as)        238\n",
      "3        (some, of, the)        179\n",
      "4         (out, of, the)        174\n",
      "5      (the, fact, that)        167\n",
      "6         (the, end, of)        149\n",
      "7        (part, of, the)        146\n",
      "8           (it, was, a)        144\n",
      "9        (there, was, a)        142\n"
     ]
    }
   ],
   "source": [
    "trigrams_df = get_ngrams_frequencies(cleaned_tokens, n=3)\n",
    "print(trigrams_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "671d7e63-a207-48f3-ab5e-90950658a5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as', 'for', 'to', 'the', 'that']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_words(trigrams_df, input_seq=(\"one\", \"of\"), n=3, k=5)\n",
    "predict_next_words(trigrams_df, input_seq=(\"the\", \"united\"), n=3, k=5)\n",
    "predict_next_words(trigrams_df, input_seq=(\"it\", \"was\"), n=3, k=5)\n",
    "predict_next_words(trigrams_df, input_seq=(\"as\", \"well\"), n=3, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91473b2-a2cd-4fec-a753-2da4de55fb14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_bert_env]",
   "language": "python",
   "name": "conda-env-nlp_bert_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
